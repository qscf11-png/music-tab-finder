"""
éŸ³è¨Šè™•ç†æ¨¡çµ„
è² è²¬å¾ YouTube ä¸‹è¼‰éŸ³è¨Šï¼Œä¸¦ä½¿ç”¨ librosa é€²è¡ŒéŸ³é«˜åµæ¸¬è½‰æ›ç‚º MIDIã€‚
"""

import os
import subprocess
import sys
from pathlib import Path

import numpy as np

# yt-dlp è¨­å®š
DOWNLOAD_DIR = Path(__file__).parent / "downloads"
DOWNLOAD_DIR.mkdir(exist_ok=True)


def _get_ytdlp_cmd():
    """å–å¾— yt-dlp çš„åŸ·è¡ŒæŒ‡ä»¤ï¼ˆä½¿ç”¨ Python æ¨¡çµ„å‘¼å«ä»¥é¿å… PATH å•é¡Œï¼‰ã€‚"""
    return [sys.executable, "-m", "yt_dlp"]


def download_youtube_audio(youtube_url: str) -> dict:
    """
    å¾ YouTube é€£çµä¸‹è¼‰éŸ³è¨Šã€‚

    å˜—è©¦è½‰æ›ç‚º WAVï¼ˆéœ€è¦ ffmpegï¼‰ï¼Œè‹¥ç„¡ ffmpeg å‰‡ç›´æ¥ä¸‹è¼‰åŸå§‹éŸ³è¨Šæ ¼å¼ã€‚

    Args:
        youtube_url: YouTube å½±ç‰‡çš„ URL

    Returns:
        dict: åŒ…å« file_path, title, duration ç­‰è³‡è¨Š
    """
    import shutil

    has_ffmpeg = shutil.which("ffmpeg") is not None
    output_template = str(DOWNLOAD_DIR / "%(id)s.%(ext)s")

    # å»ºç«‹ yt-dlp æŒ‡ä»¤
    cmd = _get_ytdlp_cmd()

    if has_ffmpeg:
        cmd += ["--extract-audio", "--audio-format", "wav", "--audio-quality", "0"]
    else:
        # ç„¡ ffmpegï¼šç›´æ¥ä¸‹è¼‰æœ€ä½³éŸ³è¨Šï¼ˆä¸è½‰æª”ï¼‰
        cmd += ["-f", "bestaudio"]

    cmd += [
        "--output", output_template,
        "--print", "after_move:filepath" if has_ffmpeg else "after_filter:filepath",
        "--print", "%(title)s",
        "--print", "%(duration)s",
        "--no-playlist",
        youtube_url,
    ]

    try:
        result = subprocess.run(
            cmd, capture_output=True, text=True, timeout=300, check=True
        )
        lines = result.stdout.strip().split("\n")
        lines = [l for l in lines if l.strip()]

        if len(lines) >= 3:
            file_path = lines[-3].strip()
            title = lines[-2].strip()
            try:
                duration = float(lines[-1].strip())
            except (ValueError, TypeError):
                duration = 0
        elif len(lines) >= 1:
            file_path = lines[0].strip()
            title = "Unknown"
            duration = 0
        else:
            return {"success": False, "error": "yt-dlp æœªç”¢ç”Ÿè¼¸å‡º"}

        # ç¢ºèªæª”æ¡ˆå­˜åœ¨
        if not os.path.exists(file_path):
            files = sorted(DOWNLOAD_DIR.glob("*"), key=lambda f: f.stat().st_mtime, reverse=True)
            if files:
                file_path = str(files[0])
            else:
                return {"success": False, "error": f"æ‰¾ä¸åˆ°ä¸‹è¼‰æª”æ¡ˆ: {file_path}"}

        return {
            "success": True,
            "file_path": file_path,
            "title": title,
            "duration": duration,
        }
    except subprocess.CalledProcessError as e:
        error_msg = e.stderr or str(e)
        if "ffmpeg" in error_msg.lower():
            return {"success": False, "error": "éœ€è¦å®‰è£ ffmpegã€‚è«‹åŸ·è¡Œ: winget install ffmpeg"}
        return {"success": False, "error": f"ä¸‹è¼‰å¤±æ•—: {error_msg[:200]}"}
    except subprocess.TimeoutExpired:
        return {"success": False, "error": "ä¸‹è¼‰è¶…æ™‚ï¼ˆè¶…é 5 åˆ†é˜ï¼‰"}


def audio_to_midi(audio_path: str, output_midi_path: str = None) -> dict:
    """
    ä½¿ç”¨ librosa é€²è¡ŒéŸ³é«˜åµæ¸¬ï¼Œå°‡éŸ³è¨Šè½‰æ›ç‚º MIDIã€‚

    ä½¿ç”¨ pyin æ¼”ç®—æ³•åµæ¸¬æ—‹å¾‹éŸ³é«˜ï¼Œé…åˆ onset detection åµæ¸¬éŸ³ç¬¦èµ·å§‹ä½ç½®ï¼Œ
    å†ä½¿ç”¨ beat tracking åˆ†æç¯€æ‹ã€‚

    Args:
        audio_path: éŸ³è¨Šæª”æ¡ˆè·¯å¾‘ï¼ˆæ”¯æ´ wav, webm, m4a ç­‰ï¼‰
        output_midi_path: è¼¸å‡º MIDI æª”æ¡ˆè·¯å¾‘

    Returns:
        dict: åŒ…å« midi_pathã€tempoã€key ç­‰è³‡è¨Š
    """
    if output_midi_path is None:
        p = Path(audio_path)
        output_midi_path = str(p.parent / (p.stem + ".mid"))

    try:
        import librosa
        import pretty_midi

        print(f"ğŸ“Š è¼‰å…¥éŸ³è¨Š: {audio_path}")
        # è¼‰å…¥éŸ³è¨Šï¼ˆlibrosa æ”¯æ´å¤šç¨®æ ¼å¼ï¼Œæœƒè‡ªå‹•ç”¨ soundfile æˆ– audioreadï¼‰
        y, sr = librosa.load(audio_path, sr=22050, mono=True, duration=180)
        print(f"   å–æ¨£ç‡: {sr}, é•·åº¦: {len(y)/sr:.1f}ç§’")

        # â”€â”€ ç¯€æ‹åµæ¸¬ â”€â”€
        tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)
        # tempo å¯èƒ½æ˜¯é™£åˆ—
        if hasattr(tempo, '__len__'):
            tempo = float(tempo[0]) if len(tempo) > 0 else 120.0
        else:
            tempo = float(tempo)
        tempo = max(60, min(200, tempo))  # é™åˆ¶åˆç†ç¯„åœ
        print(f"   åµæ¸¬ BPM: {tempo:.0f}")

        # â”€â”€ éŸ³é«˜åµæ¸¬ (pyin) â”€â”€
        # pyin æ¯” piptrack æ›´é©åˆå–®æ—‹å¾‹åµæ¸¬
        f0, voiced_flag, voiced_probs = librosa.pyin(
            y, fmin=librosa.note_to_hz('C2'),
            fmax=librosa.note_to_hz('C7'),
            sr=sr
        )

        # å°‡é »ç‡è½‰ç‚º MIDI éŸ³é«˜
        times = librosa.times_like(f0, sr=sr)

        # â”€â”€ Onset åµæ¸¬ â”€â”€
        onset_frames = librosa.onset.onset_detect(y=y, sr=sr, backtrack=True)
        onset_times = librosa.frames_to_time(onset_frames, sr=sr)

        # â”€â”€ å»ºç«‹ MIDI â”€â”€
        midi = pretty_midi.PrettyMIDI(initial_tempo=tempo)
        melody = pretty_midi.Instrument(program=0, name="Melody")
        bass_line = pretty_midi.Instrument(program=25, name="Guitar")

        # å¾ pyin çµæœä¸­æå–éŸ³ç¬¦
        notes = _extract_notes_from_pyin(f0, voiced_flag, times, onset_times)
        print(f"   åµæ¸¬åˆ° {len(notes)} å€‹éŸ³ç¬¦")

        if len(notes) < 5:
            return {
                "success": False,
                "error": "åµæ¸¬åˆ°çš„éŸ³ç¬¦å¤ªå°‘ï¼Œå¯èƒ½æ˜¯éŸ³è¨Šå“è³ªä¸ä½³æˆ–æ ¼å¼ä¸æ”¯æ´"
            }

        for note_info in notes:
            note = pretty_midi.Note(
                velocity=int(note_info['velocity']),
                pitch=int(note_info['pitch']),
                start=float(note_info['start']),
                end=float(note_info['end']),
            )
            melody.notes.append(note)

        midi.instruments.append(melody)

        # ç°¡å–®çš„å’Œå¼¦æ¨è«–ï¼ˆæ ¹æ“šéŸ³ç¬¦åˆ†å¸ƒæ¨ä¼°å’Œå¼¦é€²è¡Œï¼‰
        chords = _estimate_chord_progression(notes, tempo)
        for chord_note in chords:
            n = pretty_midi.Note(
                velocity=70,
                pitch=int(chord_note['pitch']),
                start=float(chord_note['start']),
                end=float(chord_note['end']),
            )
            bass_line.notes.append(n)

        midi.instruments.append(bass_line)

        # èª¿æ€§åˆ†æ
        key = _detect_key(notes)

        midi.write(output_midi_path)
        print(f"   âœ… MIDI å·²ç”¢ç”Ÿ: {output_midi_path}")

        return {
            "success": True,
            "midi_path": output_midi_path,
            "tempo": round(tempo),
            "key": key,
            "note_count": len(notes),
            "note": f"ä½¿ç”¨ librosa pyin åµæ¸¬åˆ° {len(notes)} å€‹éŸ³ç¬¦",
        }
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "error": f"éŸ³è¨Šåˆ†æå¤±æ•—: {str(e)}",
        }


def _extract_notes_from_pyin(f0, voiced_flag, times, onset_times):
    """
    å¾ pyin çš„çµæœæå–éŸ³ç¬¦åˆ—è¡¨ã€‚

    å°‡é€£çºŒçš„ç›¸åŒéŸ³é«˜åˆä½µç‚ºä¸€å€‹éŸ³ç¬¦ï¼Œé…åˆ onset åµæ¸¬ç¢ºå®šéŸ³ç¬¦é‚Šç•Œã€‚
    """
    notes = []
    current_pitch = None
    current_start = None
    min_duration = 0.08  # æœ€çŸ­éŸ³ç¬¦é•·åº¦ï¼ˆç§’ï¼‰

    for i in range(len(f0)):
        if voiced_flag[i] and not np.isnan(f0[i]):
            midi_pitch = int(round(librosa_hz_to_midi(f0[i])))
            midi_pitch = max(21, min(108, midi_pitch))  # é‹¼ç´ç¯„åœ

            # æª¢æŸ¥æ˜¯å¦æœ‰æ–°çš„ onset
            is_new_onset = False
            for onset_t in onset_times:
                if abs(times[i] - onset_t) < 0.05:
                    is_new_onset = True
                    break

            if current_pitch is None:
                # æ–°éŸ³ç¬¦é–‹å§‹
                current_pitch = midi_pitch
                current_start = times[i]
            elif midi_pitch != current_pitch or is_new_onset:
                # éŸ³é«˜æ”¹è®Šæˆ–æ–° onset â†’ çµæŸå‰ä¸€å€‹éŸ³ç¬¦
                duration = times[i] - current_start
                if duration >= min_duration:
                    velocity = min(120, max(60, 80 + int((duration - 0.1) * 40)))
                    notes.append({
                        'pitch': current_pitch,
                        'start': current_start,
                        'end': times[i],
                        'velocity': velocity,
                    })
                current_pitch = midi_pitch
                current_start = times[i]
        else:
            # ç„¡è²å€æ®µ â†’ çµæŸç•¶å‰éŸ³ç¬¦
            if current_pitch is not None:
                duration = times[i] - current_start
                if duration >= min_duration:
                    velocity = min(120, max(60, 80))
                    notes.append({
                        'pitch': current_pitch,
                        'start': current_start,
                        'end': times[i],
                        'velocity': velocity,
                    })
                current_pitch = None
                current_start = None

    # è™•ç†æœ€å¾Œä¸€å€‹éŸ³ç¬¦
    if current_pitch is not None and current_start is not None:
        end_time = times[-1] if len(times) > 0 else current_start + 0.25
        duration = end_time - current_start
        if duration >= min_duration:
            notes.append({
                'pitch': current_pitch,
                'start': current_start,
                'end': end_time,
                'velocity': 80,
            })

    return notes


def _estimate_chord_progression(notes, tempo):
    """
    æ ¹æ“šæ—‹å¾‹éŸ³ç¬¦ç°¡å–®æ¨ä¼°å’Œå¼¦é€²è¡Œã€‚
    æ¯å°ç¯€å–è©²å°ç¯€ä¸­å‡ºç¾é »ç‡æœ€é«˜çš„éŸ³åšç‚ºæ ¹éŸ³ã€‚
    """
    if not notes:
        return []

    beat_duration = 60.0 / tempo
    bar_duration = beat_duration * 4  # 4/4 æ‹
    total_duration = max(n['end'] for n in notes)
    chord_notes = []

    # å¸¸è¦‹å’Œå¼¦æ ¹éŸ³å°ç…§
    for bar_start in np.arange(0, total_duration, bar_duration):
        bar_end = bar_start + bar_duration
        # æ”¶é›†æ­¤å°ç¯€çš„éŸ³é«˜
        pitches_in_bar = []
        for n in notes:
            if n['start'] >= bar_start and n['start'] < bar_end:
                pitches_in_bar.append(n['pitch'] % 12)

        if not pitches_in_bar:
            continue

        # æ‰¾åˆ°å‡ºç¾æœ€å¤šæ¬¡çš„éŸ³ä½œç‚ºæ ¹éŸ³
        pitch_counts = {}
        for p in pitches_in_bar:
            pitch_counts[p] = pitch_counts.get(p, 0) + 1
        root = max(pitch_counts, key=pitch_counts.get)

        # åŠ å…¥æ ¹éŸ³ï¼ˆä½ä¸€å€‹å…«åº¦ï¼‰
        bass_pitch = 36 + root  # C2 èµ·
        chord_notes.append({
            'pitch': bass_pitch,
            'start': bar_start,
            'end': bar_end,
        })

    return chord_notes


def _detect_key(notes):
    """
    æ ¹æ“šéŸ³ç¬¦åˆ†å¸ƒåµæ¸¬èª¿æ€§ã€‚
    ä½¿ç”¨ Krumhansl-Kessler éŸ³èª¿å‰–é¢ï¼ˆç°¡åŒ–ç‰ˆï¼‰ã€‚
    """
    if not notes:
        return "C"

    NOTE_NAMES = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"]

    # è¨ˆç®—å„éŸ³åå‡ºç¾æ¬¡æ•¸
    pitch_histogram = [0] * 12
    for n in notes:
        pitch_class = n['pitch'] % 12
        duration = n['end'] - n['start']
        pitch_histogram[pitch_class] += duration

    # å¤§èª¿çš„ Krumhansl-Kessler profile
    major_profile = [6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88]

    # å˜—è©¦æ¯å€‹èª¿
    best_key = "C"
    best_corr = -1

    for shift in range(12):
        shifted = pitch_histogram[shift:] + pitch_histogram[:shift]
        # è¨ˆç®—ç›¸é—œä¿‚æ•¸
        mean_s = sum(shifted) / 12
        mean_p = sum(major_profile) / 12
        numerator = sum((s - mean_s) * (p - mean_p) for s, p in zip(shifted, major_profile))
        denom_s = sum((s - mean_s) ** 2 for s in shifted) ** 0.5
        denom_p = sum((p - mean_p) ** 2 for p in major_profile) ** 0.5

        if denom_s > 0 and denom_p > 0:
            corr = numerator / (denom_s * denom_p)
            if corr > best_corr:
                best_corr = corr
                best_key = NOTE_NAMES[shift]

    return best_key


def librosa_hz_to_midi(freq):
    """å°‡é »ç‡ (Hz) è½‰æ›ç‚º MIDI éŸ³é«˜ã€‚"""
    if freq <= 0:
        return 0
    return 69 + 12 * np.log2(freq / 440.0)


# ä¿æŒå‘å¾Œç›¸å®¹
audio_to_midi_basic = audio_to_midi


def cleanup_downloads(max_age_hours: int = 24):
    """æ¸…ç†è¶…éæŒ‡å®šæ™‚é–“çš„ä¸‹è¼‰æª”æ¡ˆã€‚"""
    import time

    now = time.time()
    for f in DOWNLOAD_DIR.iterdir():
        if f.is_file() and (now - f.stat().st_mtime) > max_age_hours * 3600:
            f.unlink()
